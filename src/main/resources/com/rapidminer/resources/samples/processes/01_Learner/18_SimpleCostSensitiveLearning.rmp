<?xml version="1.0" encoding="UTF-8"?><process version="7.3.000-SNAPSHOT">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="7.3.000-SNAPSHOT" expanded="true" name="Root">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="generate_data" compatibility="7.1.001" expanded="true" height="68" name="ExampleSetGenerator" width="90" x="45" y="34">
        <parameter key="target_function" value="polynomial classification"/>
        <parameter key="number_examples" value="300"/>
        <parameter key="number_of_attributes" value="5"/>
        <parameter key="attributes_lower_bound" value="-10.0"/>
        <parameter key="attributes_upper_bound" value="10.0"/>
        <parameter key="gaussian_standard_deviation" value="10.0"/>
        <parameter key="largest_radius" value="10.0"/>
        <parameter key="use_local_random_seed" value="false"/>
        <parameter key="local_random_seed" value="1992"/>
        <parameter key="datamanagement" value="double_array"/>
      </operator>
      <operator activated="true" class="concurrency:cross_validation" compatibility="7.3.000-SNAPSHOT" expanded="true" height="145" name="Cross Validation" width="90" x="179" y="34">
        <parameter key="enable_parallel_execution" value="true"/>
        <parameter key="leave_one_out" value="false"/>
        <parameter key="number_of_folds" value="5"/>
        <parameter key="sampling_type" value="automatic"/>
        <parameter key="use_local_random_seed" value="false"/>
        <parameter key="local_random_seed" value="1992"/>
        <parameter key="materialize_data" value="true"/>
        <process expanded="true">
          <operator activated="true" class="metacost" compatibility="7.3.000-SNAPSHOT" expanded="true" height="82" name="MetaCost" width="90" x="45" y="34">
            <parameter key="cost_matrix" value="[0.0 1.0;10.0 0.0]"/>
            <parameter key="use_subset_for_training" value="1.0"/>
            <parameter key="iterations" value="10"/>
            <parameter key="sampling_with_replacement" value="true"/>
            <parameter key="use_local_random_seed" value="false"/>
            <parameter key="local_random_seed" value="1992"/>
            <process expanded="true">
              <operator activated="true" class="parallel_decision_tree" compatibility="7.3.000-SNAPSHOT" expanded="true" name="DecisionTree (2)">
                <parameter key="criterion" value="gain_ratio"/>
                <parameter key="maximal_depth" value="20"/>
                <parameter key="apply_pruning" value="true"/>
                <parameter key="confidence" value="0.25"/>
                <parameter key="apply_prepruning" value="true"/>
                <parameter key="minimal_gain" value="0.1"/>
                <parameter key="minimal_leaf_size" value="2"/>
                <parameter key="minimal_size_for_split" value="4"/>
                <parameter key="number_of_prepruning_alternatives" value="3"/>
              </operator>
              <connect from_port="training set" to_op="DecisionTree (2)" to_port="training set"/>
              <connect from_op="DecisionTree (2)" from_port="model" to_port="model"/>
              <portSpacing port="source_training set" spacing="0"/>
              <portSpacing port="sink_model" spacing="0"/>
            </process>
          </operator>
          <connect from_port="training set" to_op="MetaCost" to_port="training set"/>
          <connect from_op="MetaCost" from_port="model" to_port="model"/>
          <portSpacing port="source_training set" spacing="0"/>
          <portSpacing port="sink_model" spacing="0"/>
          <portSpacing port="sink_through 1" spacing="0"/>
        </process>
        <process expanded="true">
          <operator activated="true" class="apply_model" compatibility="7.1.001" expanded="true" height="82" name="Apply Model" width="90" x="45" y="34">
            <list key="application_parameters"/>
            <parameter key="create_view" value="false"/>
          </operator>
          <operator activated="true" class="performance" compatibility="7.3.000-SNAPSHOT" expanded="true" height="82" name="Performance" width="90" x="179" y="34">
            <parameter key="use_example_weights" value="true"/>
          </operator>
          <connect from_port="model" to_op="Apply Model" to_port="model"/>
          <connect from_port="test set" to_op="Apply Model" to_port="unlabelled data"/>
          <connect from_op="Apply Model" from_port="labelled data" to_op="Performance" to_port="labelled data"/>
          <connect from_op="Performance" from_port="performance" to_port="performance 1"/>
          <portSpacing port="source_model" spacing="0"/>
          <portSpacing port="source_test set" spacing="0"/>
          <portSpacing port="source_through 1" spacing="0"/>
          <portSpacing port="sink_test set results" spacing="0"/>
          <portSpacing port="sink_performance 1" spacing="0"/>
          <portSpacing port="sink_performance 2" spacing="0"/>
        </process>
      </operator>
      <connect from_op="ExampleSetGenerator" from_port="output" to_op="Cross Validation" to_port="example set"/>
      <connect from_op="Cross Validation" from_port="performance 1" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <description align="left" color="yellow" colored="false" height="271" resized="true" width="620" x="40" y="194">This process is another example for cost sensitive learning, i.e. for a case where different prediction errors would cause different costs. Beside the preprocessing operator ThresholdFinder, which is also able to deliver ROC plots for two classes, another operator exist which can be used for cost sensitive learning.&lt;br/&gt;&lt;br/&gt;This operator is part of the Learner -- Meta group and is called MetaCost. It is used as any other meta learning scheme and must contain another inner learning operator, in this case the decision tree learner is used.&lt;br/&gt;&lt;br/&gt;The cost matrix used for cost sensitive learning can be defined via the matrix editor (just press the button for the parameter cost_matrix of the MetaCost operator). The basic format for the parameter cost-matrix is [k11 ... k1m; k21 ... k2m; ... ; kn1 ... knm], e.g. for a 2x2 cost matrix of a binary classification problem [0 1; 10 0]. This example means that the costs for the error of predicting the first class as the second are ten times higher than the other error type.</description>
    </process>
  </operator>
</process>
