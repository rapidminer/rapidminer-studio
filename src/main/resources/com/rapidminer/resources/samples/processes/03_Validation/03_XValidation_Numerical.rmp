<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<process version="6.4.000-SNAPSHOT">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="6.4.000-SNAPSHOT" expanded="true" name="Root">
    <process expanded="true">
      <operator activated="true" class="retrieve" compatibility="6.4.000-SNAPSHOT" expanded="true" height="60" name="Retrieve" width="90" x="45" y="30">
        <parameter key="repository_entry" value="../../data/Polynomial"/>
      </operator>
      <operator activated="true" class="x_validation" compatibility="6.4.000-SNAPSHOT" expanded="true" height="112" name="XVal" width="90" x="180" y="30">
        <parameter key="sampling_type" value="shuffled sampling"/>
        <process expanded="true">
          <operator activated="true" class="support_vector_machine_libsvm" compatibility="6.4.000-SNAPSHOT" expanded="true" height="76" name="Training" width="90" x="45" y="30">
            <parameter key="svm_type" value="epsilon-SVR"/>
            <parameter key="kernel_type" value="poly"/>
            <parameter key="C" value="1000.0"/>
            <parameter key="epsilon" value="0.0010"/>
            <list key="class_weights"/>
          </operator>
          <connect from_port="training" to_op="Training" to_port="training set"/>
          <connect from_op="Training" from_port="model" to_port="model"/>
          <portSpacing port="source_training" spacing="0"/>
          <portSpacing port="sink_model" spacing="0"/>
          <portSpacing port="sink_through 1" spacing="0"/>
        </process>
        <process expanded="true">
          <operator activated="true" class="apply_model" compatibility="6.4.000-SNAPSHOT" expanded="true" height="76" name="Test" width="90" x="45" y="30">
            <list key="application_parameters"/>
          </operator>
          <operator activated="true" class="performance_regression" compatibility="6.4.000-SNAPSHOT" expanded="true" height="76" name="Evaluation" width="90" x="238" y="30">
            <parameter key="absolute_error" value="true"/>
            <parameter key="relative_error" value="true"/>
            <parameter key="normalized_absolute_error" value="true"/>
            <parameter key="root_relative_squared_error" value="true"/>
            <parameter key="squared_error" value="true"/>
            <parameter key="correlation" value="true"/>
          </operator>
          <connect from_port="model" to_op="Test" to_port="model"/>
          <connect from_port="test set" to_op="Test" to_port="unlabelled data"/>
          <connect from_op="Test" from_port="labelled data" to_op="Evaluation" to_port="labelled data"/>
          <connect from_op="Evaluation" from_port="performance" to_port="averagable 1"/>
          <portSpacing port="source_model" spacing="0"/>
          <portSpacing port="source_test set" spacing="0"/>
          <portSpacing port="source_through 1" spacing="0"/>
          <portSpacing port="sink_averagable 1" spacing="0"/>
          <portSpacing port="sink_averagable 2" spacing="0"/>
        </process>
      </operator>
      <connect from_op="Retrieve" from_port="output" to_op="XVal" to_port="training"/>
      <connect from_op="XVal" from_port="averagable 1" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <description align="left" color="yellow" colored="false" height="249" resized="true" width="908" x="29" y="149">In many cases not the learned model is of interest but the accuracy of the model. One possible solution to estimate the predictiveness of the learned model is to apply it to labeled test data and calculate the number of prediction errors (or other performance criteria). Since labeled data is rare, other approaches to estimate the performance of a learning scheme are often used. This process demonstrates &amp;quot;cross validation&amp;quot; in RapidMiner.&lt;br&gt;&lt;br&gt;Cross validation divides the labelled data in training and test sets. Models are learned on training data and applied on test data. The prediction errors are calculated and averaged for all subsets. This building block can be used as inner operator for several wrappers like feature generation / selection operators.&lt;br&gt;&lt;br&gt;This is the first example of a more complex process. The operators build a tree structure. For now it is enough to accept that the cross validation operator demands an example set as input and delivers a vector of performance values as output. Additionally it manages the division into training and test examples. The training examples are used as input for the training learner which delivers a model. This model and the test examples form the input of the applier chain which delivers the performance for this test set. The results for all possible test sets are collected by the cross validation operator. Finally the average is built and delivered as result.</description>
    </process>
  </operator>
</process>
